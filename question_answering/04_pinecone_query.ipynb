{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Pinecone Query\n",
    "\n",
    "Query the index created in notebook 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pinecone\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.display import Markdown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_CHAT_MODEL = os.getenv('OPENAI_CHAT_MODEL', 'gpt-3.5-turbo')\n",
    "OPENAI_EMBED_MODEL = os.getenv('OPENAI_EMBED_MODEL', 'text-embedding-ada-002')\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_INDEX = os.getenv('PINECONE_INDEX', 'openai-dsm100-2022-oct-transcriptions')\n",
    "PINECONE_ENV = os.getenv('PINECONE_ENV', 'us-east1-gcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# configure pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question01 = \"\"\"\n",
    "a. AI has a long history with ups and downs, over-optimistic expectations, and the\n",
    "industrial period. At present, AI is in the era of:\n",
    "\n",
    "Select ALL statements that apply.\n",
    "\n",
    "[3 marks]\n",
    "i. Big data.\n",
    "ii. Deep learning.\n",
    "iii. Robotics.\n",
    "iv. General AI.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question02 = \"\"\"\n",
    "f. The more background knowledge an intelligent agent can use – the more intelligent\n",
    "behaviour it can exhibit. Background knowledge can include:\n",
    "[3 marks]\n",
    "\n",
    "Select ALL statements that apply. \n",
    "\n",
    "(i). Problem-specific knowledge\n",
    "(ii). Declarative knowledge\n",
    "(iii). Procedural knowledge\n",
    "(iv). A dataset\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 100}},\n",
      " 'total_vector_count': 100}\n"
     ]
    }
   ],
   "source": [
    "def get_pinecone_index(index_name: str) -> pinecone.index.Index:\n",
    "    # connect to index\n",
    "    index = pinecone.Index(index_name)\n",
    "    \n",
    "    # view index stats\n",
    "    print(index.describe_index_stats())  \n",
    "\n",
    "    return index  \n",
    "\n",
    "# test the function\n",
    "index = get_pinecone_index(PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings(text: str) -> list:\n",
    "    result = openai.Embedding.create(\n",
    "            input=[text], engine=OPENAI_EMBED_MODEL)\n",
    "\n",
    "    return result['data'][0]['embedding']\n",
    "\n",
    "# test the function\n",
    "#get_text_embeddings(question01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone_index(index: pinecone.index.Index,\n",
    "                         query: str,\n",
    "                         k: int = 5,\n",
    "                         include_metadata=True) -> list:\n",
    "    # get embeddings for query\n",
    "    query_embedding = get_text_embeddings(query)\n",
    "\n",
    "    # query index\n",
    "    return index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=k,\n",
    "        include_metadata=include_metadata\n",
    "    )\n",
    "\n",
    "# test the function\n",
    "#query_pinecone_index(index, question02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Answer the question based on the context below.\n",
       "\n",
       "Context:\n",
       "[music]In this topic, we discussed how intelligent agents can find solutions and make decisions.  We can see that uninformed or blind search, informed or heuristic search, and we also discuss that domain-specific knowledge can improve decision-making substantially.  The more agent knows and remembers from the past, the more intelligent behavior it can exhibit.  We also talked about meta-learning or meta-reasoning.  When different search strategies are analyzed and compared, in what situation, what strategy would work best.  If you're interested in this topic, please check the recommended literature.  Of course, there are plenty of resources available in our online library and around. \n",
       "\n",
       "---\n",
       "\n",
       "[music]-In this mini lecture, we will talk about knowledge-based agents.  We have already seen in the previous topics that knowledge makes an agent more intelligent, be it domain-specific knowledge, or knowledge of the past experience, what worked well and what did not.  The more an agent knows and remembers, the better decisions it can make.  Agents that are using knowledge for making decisions are called knowledge-based agents.  This component of a knowledge-based agent is called, unsurprisingly, a knowledge base.  Knowledge has to be encoded in a machine processable way, usually, using knowledge representation languages.  What is knowledge?Generally, there is no clear separation in the means between data, knowledge, and information.  It is often the case even in computer science.  It is, well, stating explicitly what we will consider as such in this module.  Data are facts.  Typically, data are encoded as a table.  For example, if a table stores various chemical element sand their freezing and melting points, then an example of a data item or a fact would be, melting point of helium is -272.  2 celsius.  Typically, knowledge is encoded as a set of rules.  For example, if the temperature is below the melting point, then the chemical substance is in a liquid state.  More advanced knowledge can be represented in the form of an executable model.  For example, a metabolic model captures our knowledge about the metabolic pathways, and molecular mechanisms of a particular organism.  Information is a more generic term that combines data and knowledge.  Problems-specific and domain specific knowledge is called background knowledge.  This can be available to a knowledge-based agent from the very beginning\n",
       "\n",
       "Question: \n",
       "f. The more background knowledge an intelligent agent can use – the more intelligent\n",
       "behaviour it can exhibit. Background knowledge can include:\n",
       "[3 marks]\n",
       "\n",
       "Select ALL statements that apply. \n",
       "\n",
       "(i). Problem-specific knowledge\n",
       "(ii). Declarative knowledge\n",
       "(iii). Procedural knowledge\n",
       "(iv). A dataset\n",
       "\n",
       "Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_prompt(index: pinecone.index.Index,\n",
    "                  query: str, \n",
    "                  prompt_limit: int = 3750) -> str:\n",
    "    prompt = \"\"\n",
    "    \n",
    "    # query pinecone for matching transcripts\n",
    "    pinecone_results = query_pinecone_index(index, query)\n",
    "\n",
    "    # get relevant contexts\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in pinecone_results['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    \n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= prompt_limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# test the function\n",
    "prompt = create_prompt(index, question02)\n",
    "display(Markdown(prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question:\n",
       "f. The more background knowledge an intelligent agent can use – the more intelligent\n",
       "behaviour it can exhibit. Background knowledge can include:\n",
       "[3 marks]\n",
       "\n",
       "Select ALL statements that apply. \n",
       "\n",
       "(i). Problem-specific knowledge\n",
       "(ii). Declarative knowledge\n",
       "(iii). Procedural knowledge\n",
       "(iv). A dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Answer: (i). Problem-specific knowledge\n",
       "(ii). Declarative knowledge\n",
       "(iii). Procedural knowledge"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ask_question(index: pinecone.index.Index,\n",
    "                  query: str, \n",
    "                  prompt_limit: int = 3750) -> str:\n",
    "\n",
    "    # create prompt\n",
    "    prompt = create_prompt(index, query, prompt_limit)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=OPENAI_CHAT_MODEL,\n",
    "        messages=[\n",
    "            { 'role': 'user', 'content': prompt }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# test the function\n",
    "answer = ask_question(index, question02)\n",
    "display(Markdown('Question:' + question02))\n",
    "display(Markdown('Answer: ' + answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question:\n",
       "a. AI has a long history with ups and downs, over-optimistic expectations, and the\n",
       "industrial period. At present, AI is in the era of:\n",
       "\n",
       "Select ALL statements that apply.\n",
       "\n",
       "[3 marks]\n",
       "i. Big data.\n",
       "ii. Deep learning.\n",
       "iii. Robotics.\n",
       "iv. General AI.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Answer: i. Big data.\n",
       "ii. Deep learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = ask_question(index, question01)\n",
    "display(Markdown('Question:' + question01))\n",
    "display(Markdown('Answer: ' + answer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
