{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Pinecone Generative Question-Answering\n",
    "\n",
    "reference: [Generative Question-Answering with Long-Term Memory](https://www.pinecone.io/learn/openai-gen-qa/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.8/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pinecone\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.display import Markdown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment\n",
    "\n",
    "reference: [Using .env Files for Environment Variables in Python Applications](https://dev.to/jakewitcher/using-env-files-for-environment-variables-in-python-applications-55a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_CHAT_MODEL = os.getenv('OPENAI_CHAT_MODEL', 'gpt-3.5-turbo')\n",
    "OPENAI_EMBED_MODEL = os.getenv('OPENAI_EMBED_MODEL', 'text-embedding-ada-002')\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_INDEX = os.getenv('PINECONE_INDEX', 'openai-dsm100-2022-oct-transcriptions')\n",
    "PINECONE_ENV = os.getenv('PINECONE_ENV', 'us-east1-gcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure openai\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Chat Completions\n",
    "\n",
    "### References\n",
    "\n",
    "- [Chat completions](https://platform.openai.com/docs/guides/chat)\n",
    "- [How to format inputs to ChatGPT models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-6pd3lfRTNDF7OrBg3epVhKFvN7XKW at 0xffff8750ab30> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Orange who?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1677762893,\n",
       "  \"id\": \"chatcmpl-6pd3lfRTNDF7OrBg3epVhKFvN7XKW\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 5,\n",
       "    \"prompt_tokens\": 38,\n",
       "    \"total_tokens\": 43\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=OPENAI_CHAT_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Orange who?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSM100-2022-OCT</td>\n",
       "      <td>Module information</td>\n",
       "      <td>Module introduction video</td>\n",
       "      <td>https://learn.london.ac.uk/mod/page/view.php?i...</td>\n",
       "      <td>-Welcome to AI Module. Artificial intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSM100-2022-OCT</td>\n",
       "      <td>Module information</td>\n",
       "      <td>Meet the team</td>\n",
       "      <td>https://learn.london.ac.uk/mod/page/view.php?i...</td>\n",
       "      <td>[music]-Welcome to the AI module. My name is L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSM100-2022-OCT</td>\n",
       "      <td>Topic 1: Introduction</td>\n",
       "      <td>Lecture: Introduction to Topic 1</td>\n",
       "      <td>https://learn.london.ac.uk/mod/page/view.php?i...</td>\n",
       "      <td>Welcome to topic one, Introduction to AI. In t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            course                  topic                             title  \\\n",
       "0  DSM100-2022-OCT     Module information         Module introduction video   \n",
       "1  DSM100-2022-OCT     Module information                     Meet the team   \n",
       "2  DSM100-2022-OCT  Topic 1: Introduction  Lecture: Introduction to Topic 1   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://learn.london.ac.uk/mod/page/view.php?i...   \n",
       "1  https://learn.london.ac.uk/mod/page/view.php?i...   \n",
       "2  https://learn.london.ac.uk/mod/page/view.php?i...   \n",
       "\n",
       "                                          transcript  \n",
       "0  -Welcome to AI Module. Artificial intelligence...  \n",
       "1  [music]-Welcome to the AI module. My name is L...  \n",
       "2  Welcome to topic one, Introduction to AI. In t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_source = pd.read_csv('data/output/transcripts.csv')\n",
    "\n",
    "print(df_source.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_source.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = df_source.iloc[43].transcript\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[transcript], engine=OPENAI_EMBED_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'][0]['embedding'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transcript(text: str, window: int = 20, stride:int = 4) -> list:\n",
    "    \"\"\"\n",
    "    Split transcript into parts equal to the window size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The transcript to split.\n",
    "\n",
    "    window : int, optional\n",
    "        The number of sentences to combine into a single part, by default 20\n",
    "\n",
    "    stride : int, optional\n",
    "        The number of sentences to 'stride' over, used to create overlap.\n",
    "    \"\"\"\n",
    "    sentences = text.split('.')\n",
    "\n",
    "    parts = []\n",
    "    for i in range(0, len(sentences), stride):\n",
    "        part = '. '.join(sentences[i:i+window])\n",
    "        parts.append(part)\n",
    "\n",
    "    return parts\n",
    "\n",
    "# # test the function\n",
    "# transcript = df_source.iloc[43].transcript\n",
    "# split = split_transcript(transcript, window=4, stride=2)\n",
    "\n",
    "# print(len(split))\n",
    "# display(Markdown('# Original'))\n",
    "# display(Markdown(transcript))\n",
    "\n",
    "# display(Markdown('# split[0]'))\n",
    "# display(Markdown(split[0]))\n",
    "\n",
    "# display(Markdown('# split[1]'))\n",
    "# display(Markdown(split[1]))\n",
    "\n",
    "# display(Markdown('# split[-1]'))\n",
    "# display(Markdown(split[-2]))\n",
    "\n",
    "# display(Markdown('# split[-1]'))\n",
    "# display(Markdown(split[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc7856ee638496698d04760550bb618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'course': 'DSM100-2022-OCT',\n",
       " 'topic': 'Module information',\n",
       " 'title': 'Module introduction video',\n",
       " 'url': 'https://learn.london.ac.uk/mod/page/view.php?id=96059&forceview=1',\n",
       " 'text': \" This module will include four theoretical topic sand six topics of more practical nature.  We will focus on concrete AI systems and case studies.  You will have an opportunity to learn how they're built and how they're working.  After the end of this module, you should be able to critically evaluate key issues in agent-based system, knowledge system, robotics, automated reasoning, and problem-solving, represent tasks, environments, and outline strategies for intelligent agents, compare the adequacy and efficiency of different reasoning approaches.  We form a deep researched analysis of a particular artificial intelligence method and their use, apply AI techniques within the context of a substantial research project.  I wish you very best of luck with this module. \"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_split_dataset(df_source:pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Create a list of dictionaries containing the split transcript parts.\n",
    "    \"\"\"\n",
    "    # process each row\n",
    "    dataset = []\n",
    "    for i, row in tqdm(df_source.iterrows(), total=df_source.shape[0]):\n",
    "        # split the transcript into parts\n",
    "        parts = split_transcript(row.transcript)\n",
    "\n",
    "        # create a dictionary for each part\n",
    "        for part in parts:\n",
    "            data = {\n",
    "                'course': row['course'],\n",
    "                'topic': row['topic'],\n",
    "                'title': row['title'],\n",
    "                'url': row['url'],\n",
    "                'text': part\n",
    "            }\n",
    "            dataset.append(data)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# test the function\n",
    "split_dataset = create_split_dataset(df_source)\n",
    "print(len(split_dataset))\n",
    "split_dataset[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_database(index_name: str, dimension: int, metadata_config: dict = None):\n",
    "    \"\"\"\n",
    "    Create a vector database in pinecone.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    index_name : str\n",
    "        The name of the index to create.\n",
    "\n",
    "    dimension : int\n",
    "        The dimension of the vectors to be stored in the index.\n",
    "\n",
    "    metadata_config : dict, optional\n",
    "        The metadata configuration for the index, by default None\n",
    "    \"\"\"\n",
    "    # check if index already exists (it shouldn't if this is first time)\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        # if does not exist, create index\n",
    "        pinecone.create_index(\n",
    "            index_name,\n",
    "            dimension=dimension,\n",
    "            metric='cosine',\n",
    "            metadata_config=metadata_config\n",
    "        )\n",
    "    # connect to index\n",
    "    index = pinecone.Index(index_name)\n",
    "    \n",
    "    # view index stats\n",
    "    print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# create the pinecone index\n",
    "index_dimension = 1536\n",
    "metadata_config = {\n",
    "    'indexed': ['topic', 'title']\n",
    "}\n",
    "\n",
    "create_vector_database(PINECONE_INDEX, index_dimension, metadata_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1',\n",
      " 'metadata': {'color': 'red', 'shape': 'circle'},\n",
      " 'values': [0.4, 0.5, 0.6, 0.7]}\n"
     ]
    }
   ],
   "source": [
    "v2 = pinecone.Vector(\n",
    "    id=\"1\",\n",
    "    values=[0.4, 0.5, 0.6, 0.7], \n",
    "    metadata={\"color\": \"red\", \"shape\": \"circle\"})\n",
    "\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c02cc4ea7e840e68514b8016612a7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1585ec57e714610a81c9c142b9970fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f2291066be4fb09b690819f449acee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a8f050988546478284761c9188dd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d94d881cf64cdfb776c930578a50d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c8733b0fff48c886444b1f5b3e6135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480ffc3c9ef94a849ca1730c530d8fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f3273829c4470389d016ed1ff214b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341eb7acffd84365aeb9be56e99cfd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd190e25a5f47f78177fa4d1bdd816e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9903038369be4cb6bb179aff7a80a2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba4494f37094c64a8eb50a9a3be14cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7af037c74341f99ee4764c4b881ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3300594f3e44789c961ee164d10370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdb2fc2e1444c8ca2516bd87a131d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e8212a486340d7b4399d52a6c3cdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899518417d8e4291bdf275766a0df2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c140760a08ee49deb40634b135b4cd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2f4666902248fb98a8a9078a0aadf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c6cae5f2f64506babfacd62a05943a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22abbac5b47d4e78bc274fa92b14f6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338dc6170be74e7bbd32675c9d0d2a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98634cdb8e9944efa06ba94671e7a475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4905250d375b45deb81d311c37d2467f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972328e8370b4a45ab4e341a0861ff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6d54db924344f8828a3750b4c1a8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f596a443ca5e46bf8f3a0c14af944fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c34d2f8bb84217a0d3411628725bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99475c0f20a74694963e1dd100dccf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d612510ebb44aabadd0eb65bec1574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c27da040f1d48d9abaa58624ee39a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_vectors_to_index(data: list, index_name: str, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Add vectors to the pinecone index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        The data to add to the index.\n",
    "\n",
    "    index_name : str\n",
    "        The name of the index to add the vectors to.\n",
    "\n",
    "    batch_size : int, optional\n",
    "        The number of vectors to add to the index at a time, by default 100\n",
    "    \"\"\"\n",
    "    # connect to index\n",
    "    index = pinecone.Index(index_name)\n",
    "\n",
    "    # create batches\n",
    "    item_id = 0\n",
    "    batches = [data[i:i+batch_size] for i in range(0, len(data), batch_size)]\n",
    "\n",
    "    # add vectors to index\n",
    "    for batch in tqdm(batches):\n",
    "        # create a list of vectors\n",
    "        vectors = []\n",
    "        for data in tqdm(batch):\n",
    "            # do not handle empty vectors\n",
    "            if data['text'] == '' or data['text'] == ' ':\n",
    "                continue\n",
    "\n",
    "            # get the vector\n",
    "            res = openai.Embedding.create(\n",
    "                input=[data['text']], engine=OPENAI_EMBED_MODEL\n",
    "            )\n",
    "            vector = res['data'][0]['embedding']\n",
    "\n",
    "            pine_vector = pinecone.Vector(id=str(item_id), values=vector, metadata=data)\n",
    "            #print(pine_vector)\n",
    "\n",
    "            vectors.append(pine_vector)\n",
    "            item_id += 1\n",
    "\n",
    "        # add vectors to index\n",
    "        index.upsert(vectors=vectors)\n",
    "\n",
    "add_vectors_to_index(\n",
    "    data=split_dataset,\n",
    "    index_name=PINECONE_INDEX,\n",
    "    batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
