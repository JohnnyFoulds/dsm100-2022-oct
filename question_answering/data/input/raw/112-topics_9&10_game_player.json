{
  "course": "DSM100-2022-OCT",
  "topic": "Topics 9&10: Game Player",
  "title": "Lecture: Game player case study introduction",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96425&forceview=1",
  "transcript": "[music]Welcome to the Game Playing AI case study.Now I'm really excited to bring you this content, because for me,it's been a really fascinating learning journey,learning all about the current technology that's used to play games using AI,and applying my past knowledge around neural networksand reinforcement learning and other things to this new topics.I've really enjoyed learning about it.I hope you enjoy learning about it from me.First of all, what I want to say is, what are we doing here?We're going to be looking at the 2015 research paper from DeepMind,where they develop this system called Deep Q Networks,and they built a playing agent using this technology,which was able to get human competitive levelsof game play technique across a rangeof different retro video games, specifically Atari.Now, if you don't know what Atari is, the Atari 2600 was a video game consolefrom the 1980s, which was really popular.One of the first consoles that had games like Space Invaders,Asteroids, Breakouts, and all very classic,very well-known iconic games.It had simplified versions of the arcade gamesand loads of people have them, and its great fun.Some of the games are really challenging and very difficultto learn to play using AIs.The thing that made this paper interestingwas that actually they only fed to the AIwith the graphics on the screen.The idea is that the AI would learn how to play the gamejust by looking at what was on the screen.This is part of the research trajectory that's in process in AI researchat the moment towards generalized AI, where you can get thingswhich can just learn how to do a task without being givenreally specific detailed information about that task.That's exactly what we're going to be developing in this course,a generalized AI system, which can play a range of video gameswithout being told anything about how you actually goabout playing those games.Yes, it's really interesting.I'm going to go now through the different weeks of content,which is of modules or weeks of content, which we have for you.The first module is a history module.We're going to be looking at, of course, Deep Blue,the chess playing system from 1997.We're going to go further back than that, back to the 1950swith Shannon and Turing working on very early chess playing systems.We're not going to go into huge amount of detail.We're just going to get an overview of some of the milestonesthat are reached, and we're even going to getinto the current century.Wow, and look at some of the latest work around video game playing,and actually the chess playing and the checkers playing and stuffis ongoing work, and also poker playing as well.Lots of interesting systems to look out there.That's the first section of the course.In the second section of the course, I'm not going to try and scare you offwith a horrible equation [chuckles].Don't worry, but what we're going to do, you see that equation up there?If you're like me, you might see that and find that a little bit intimidating,or at least I did when I was doingmy master's course, and some of you are going to be doingbachelor's or whatever different courses.You might find that equation looking pretty gnarly to you.Now what I'll say is when I studied neural networksat the master's level, I had a tutor, who's a brilliant tutor,really encouraged me to dig deep into my knowledge and learn a lot more.He used to throw equations right on the board.The whole lecture was just like a massive setof hand-drawn equations on the board, and now I'd just be sitting there saying,I don't know what any of those equations do,but the way I learned what they did do is I got the textbook,and I went home and I spent ages picking all the equations apartand finding out exactly what every term in the expression meantand how that it was actually a neural networkthat could learn something.What I'm going to do is I'm going to show you partof that process in this course.I'm going to take this, for example, which is the loss function.This basically says how an AI agent can look into the futureand predict what's going to happen and then therefore knowwhether it's doing the right thing or not, that kind of thing.We're going to take this and break it apart and lookat every little element of it, and then further work into the codeand see how each bit of this equation ends up as a mechanical piece of code,if you like.That's what we're going to be doing in the second section of the course,formalizing how an AI can go about learning how to play a game.In the third section of the course, what are we goingto be looking at is tooling.What did we mean by tooling?These are the tools that we're going to be using to implement this DQN agent.The first tool we're going to be looking at in detailis the OpenAI gym environment.This is a system which allows you to essentially present your AI systemwith a unified interface with which it can interactwith a whole bunch of different tasks.For example, there's a 2D physics engine taskover there, which is trying to learn how to walk alongwith that ED-209 Robocop creature.Then that one in the middle is actually our own custom gym,so you can make your own environments.That one we programmed in Pygame because we couldn't showthe original Atari games because of copyright reasons,so we made our own one, but it was fairly easy to wrap that upand make it visible through the OpenAI system,so we learned all about that.That third one up there is a Lunar Lander, which is another example.There's loads of ready-made gyms in OpenAI gym.It's going to be a really great tool for you to learn about in general, anyway.I'm sure you'll enjoy it.The second tooling, now time for the flashing lights.Watch out if you're sensitive to flashing lights,but basically what we're looking at here is a neural network.What we're going to be learning about is the Keras neural network library.Now this isn't a neural networks course.We don't have time to teach you everything you need to knowabout neural networks, but I'm going to give youa crash course in neural networks.Specifically, I'm going to go into detail on the convolutional neural networks,which are a particular type of neural networkwhich is very good at processing images.What we're looking at here is an image of what a real neural network.Once it's been trained, what it sees when it's playing a game.We're feeding the neural network with screenshots from the game,and this is what it's turning them into.It's learned how to extract salient information about the gameand use that to then decide what to do.You're going to learn all about how that works.Then the fourth section of the course, we're actually going to take the formalismwhich we developed in week two or the second section,and we're going to express that into code.We're going to see how equations like this one can be broken apartand turned into mechanical Python code, so you can really geta good understanding.I don't know about you, but often when I see equations,I prefer to go and look at the code because I read the code,and I can understand mechanically, oh, those numbers are going over there,and those numbers are being turned into those.I can see mechanically what's happening so that helps me understandthe equations.What we'll do is we'll be going backwards and forwards between the equationsand the code, and getting a really good understandingof exactly what this thing is doing.Also in week four, we'll actually see the final neural networkand the agent system playing a game.In this instance, it's not playing it brilliantly well,but you can see, it's certainly tracking the balland getting to bounce it off the bat and scoring a few points there.I'm going to give you some pre-trained neural networks,because it takes up to 48 hours or even more to trainone of these networks, and actually you may not have accessto sufficiently powerful hardware.What I've done is I've trained a few different example networks,including one that you can run to play the original Atari Breakout gamefrom the research paper, which is very good at playing,but also one that plays our clone of the Breakout game,which didn't go quite as well, but it still certainly knowshow to play it a bit.We're going to see both of those, and I'll give you the pre-trained model,and you will be able to run it on your own machines without needingtoo much power to do that. It should run on regular type of laptops.We're going to give you that, but also show youhow you could have trained at yourself and talk abouthow I went about training it.In the final section of the course, I'm going to be fightingwith the machines, because we're going to be talkingabout the state-of-the-art in game playing AIs,especially thinking about how good are these things at playing games,and then we're going to be thinking about the ethics of this.We're going to be thinking, is it ethical?What are the impacts that building superhuman game player AIs?What is the effect of that on people who play games?For example, Lee Sedol, the Go player, who was beaten by the AlphaGo system.He stopped playing Go after that.Was that positive or negative? I don't know.We're going to be thinking about those ethical questionsand thinking about what we're doing when we're building these AI systems,whether it's the right thing to do, or whether we should be takingcertain things into consideration.That is the end of the course.Just to summarize, really looking forward to seeing your reaction to this course.This material, I think, I've really enjoyed making it,hope you enjoy it, and hope that you learned a lotabout how it's possible to build real game playing AIs using Python and Kerasand OpenAI gyms, and also hope that you gainsome real confidence about looking at these research papersand breaking those equations apart, because I'm going to show youhow I go about doing that.I hope that really is effective in this course, and that you enjoyall of the learning that we have for you."
}