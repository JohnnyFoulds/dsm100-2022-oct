{
  "course": "DSM100-2022-OCT",
  "topic": "Topic 1: Introduction",
  "title": "Lecture 2:  Milestones in the history of AI",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96080&forceview=1",
  "transcript": "In this mini-lecture with a go through the history of AI.It has its ups and downs,over-optimistic expectations, and AI winter.By now, say AI research trends are from resetand AI industry is essential for the world's economy.The beginning of AI dates back more than seven decades.The first book that is now considered as AI was done in 1943,by Warren McCulloch and Walter Pitts.They propose a model of artificial neuronsin which each neuron can be switched on or off.The on/off switch depends on the simulation of sufficient number of neighboring neurons.They showed that any computable function can be computedby some network of connected neurons,including also logical connectors like and or not.McCulloch and Pitt's also suggested that suitably defined networks could learn. Two undergraduate students from Harvard,Marvin Minsky, and Dean Edmondsbuild the first neural network computer in 1950s,the [?] It was built from 3,000 vacuum tubesand pilot mechanism from a B24 bomber to simulate a network of 40 neurons.The most influential work in AI was done by Alan Turing.In particular in his lecture in 1947at the London Mathematical Society and then his article in 1950,Computing Machinery and Intelligence,he introduced the Turing test, machine learning,genetic algorithms, and reinforcement learning.The term AI was coined in 1956.McCarthy convinced Minsky, Claude Shannon,and Nathaniel Rochester to bring together  US researchers interested in automata theory,neuron maths,and the study of intelligence for a two months workshop in Dartmouth College.This is considered to be the official birthplace of the field of AI.The agenda of the workshop is two months, 10 man study of artificial intelligence.The study is to proceed on the basis of the conjecturethat every aspect of learning or any other feature of intelligencecan in principle be so precisely described thata machine can be made to simulate it.AI became a separate field of researchbecause none of the existing fields attempted to duplicate human creativity,self-improvement, and language use.AI combined computer science and also building machines.The era of great expectations and 15 and 16was referred to McCarthy as a period, \"Look Ma, no hands.\"At those times, computers were viewed as just a little bit more than arithmetic devices.Any book showing that they can do more and be more intelligent was astonishing.The examples are Logic Theorist by Newell and Simonpresented at the Dartmouth workshopis a reasoning program capable of proving many theorems.Then they developed general problem solver.It was designed to imitate human problem-solving protocols.It could solve puzzles.Arthur Samuel developed programs for checkersthat learned to play at a strong armature level.McCarthy developed AI programming language Lisp.It was the dominant programming language, particularly in US for 30 years.The AI programming language Prologue became more popular in Europe.In 1958, McCarthy describes the program Advice Taker.It is considered to be first complete AI system.The program was designed to use knowledge to search for solutions to problems.It included not only domain-specific knowledge but also general knowledge of the world.For example, axioms could be used to generate a plan to drive to the airport.The program could accept new axioms,allowing it to achieve competence in new areas without being reprogrammed.Thus Advice Taker embodied the principlesof knowledge representation and reasoning.That it is useful to have a formal explicit representation of support and its workingsand to be able to reason over it.Cordell Green developed question answering and planning systemsbased on the general purpose methos for logical reasoning.Shakey robotic project at Stanford Research Institutewas the first to demonstrate complete integration of logical reasoningand physical activity.There are researchers who will not shyin making predictions about the success of AI.When your search predictions were over optimisticwithout acknowledging many of the difficulties in developing AI systems. Early AI systems didn't include knowledge models. A typical example is machine translation.US National Research Council funded machine translation of scientific papersfrom Russian to English after the Sputnik launch in 1957.Initially, it was thought that basic grammar rulesand a dictionary would be enough to capture the meaning of the text.The famous example is the translation of the spirit is willingbut the flesh is weakas the vodka is good but the meat is rotten.Natural languages are ambiguous and translation requires background knowledge.Soon after that, all US government funding of translation projects was canceled.Another difficulty is computational complexity and combinatorial explosion.Early AI systems were not easily scalable.Computational power also was limited.For example, genetic algorithms could not be implementedby simple random mutations of the code.More than genetic algorithms use better representations.That was the main criticism of AI in the [?] reported in 1973after which the UK Government stopped funding AI research.The period of expert systems or knowledge-based system is the end of '60sup to '90s.Problem-solving approach during the early years of AIwas to include general purpose reasoning to find a complete solution.Such an approach is considered as a weak methodbecause also generally doesn't scale up to large or difficult problems.The alternative approach is to use more powerful domain-specific knowledge. Examples of such systems are Dendral by Buchanan et al.The problem was to infer a chemical structure from the informationprovided by a mass spectrometer.The na√Øve version of the program generated all possible structuresconsistent with the input.However, this is intractable even for a moderate-sized molecule.The Dendral researchers consulted with chemistsand found that they worked with well-known patternscorresponding to typical sub-structures like [?] subgroups.This reduces the search space enormously.Dendral was the first successful knowledge-intensive system.Its expertise derived from a large number of special-purpose rules.Mycin by Feigenbaum was designed to diagnose blood infections.It contained about 450 rulesand performed as well as some expertsand considerably better than junior doctors.AI became an industry in 1980s.R1 is the first commercial expert systemthat began operation in the Digita Equipment Corporation in 1982.The program helped configure orders for new computer systems.By 1986,it was saving the company an estimated $40 million a year.By 1988, DuPont had 100 expert systems in use,saving an estimated $10 million a year.Overall, the AI industry boomed from a few million dollars in 1980 tobillions in 1988.Hundreds of companies were building expert systems, vision systems, and robots.Soon after that, came a period of the AI winterin which many failed to deliver the extravagant promises.Nowadays, AI industry is flourishing.According to McKinsey Global Institute's research,AI could deliver an additional output of $13 trillion to support the economy by 2030.The brittleness of expert systemsled to a new more scientific approach incorporating probabilityrather than Boollean logic and machine learning rather than hand-coding.In 1980s,Perl's development of Bayesian networks for a rigorousand efficient formalism for representing uncertain knowledge,and practical algorithms for probabilistic reasoning.As achievement was shared benchmark problem sets.UC Irvine repository for machine learning datasets.The International Planning Competition.The LibriSpeech corpus for speech recognition.The MNIST data set for handwritten digital recognition,and so on. The next stage was the beginning of the Big data era.It is characterized by remarkable advances in computing power,creation of World Wide Web,and creation of very large datasets.Trillions of words of text, billions of images,billions of hours of speech and video, and genomic data,vehicle tracking data, social network data, and so on.This led to development of algorithms to work with big un-labeled data sets.The availability of big dataand shift towards machine learning helped AI to recover commercial attractiveness.The next phase is deep learning.Deep Learning refers to neural networks with multiple layers.Experiments with such networks were carried out as far back as 1970s.Conventional neural networks found some successin handwritten digit recognition in 1990s.It was not until 2011however, that the DL message really took off.This first decoded speech recognition and the visual object recognitionin 2012 competition DL systemby Geoffrey Hinton from University of Torontodemonstrated a dramatic improvement over other systems.Since then, DL systems exceeded human performance on some vision tasks.Similar advances were made in speech recognition, machine translation,medical diagnosis, and game playing.The use of DL contributed to winning AlphaGo over leading human GO players.In this mini-lecture, we talked about the history of AI research,its milestones, examples systems, and also about researchers working in AI."
}