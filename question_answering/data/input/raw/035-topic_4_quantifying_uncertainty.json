{
  "course": "DSM100-2022-OCT",
  "topic": "Topic 4: Quantifying uncertainty",
  "title": "Lecture 2: Crash course in probability theory",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96199&forceview=1",
  "transcript": "[music]Probability series, well-established series with its notions,rules, and formulas.In this mini-lecture, we will take a bit of more AIand agent-oriented approach to probabilities.Probabilistic assertions are about possible worlds,and about how probable possible worlds are.The set of all possible worlds is called the sample set and denotedas a capital omega, Ω.The possible worlds, denoted as small case omega, ω,are mutually exclusive and exhaustive.Two possible worlds cannot be both the case.If one world is the case, then no other can be.For example, if we roll two dice, there are 36 possible worlds,one and one, one and two, one and three,and so a fully specified probability modelassesses a numerical probability be with each possible world.We will consider discrete countable sets of worlds.It is interesting to consider the continuous case,but it is less relevant to AI and agents.Basic axioms of probability theory says that every possible worldhas a probability between zero and one and that the total probabilityof all possible worlds is one.[?] you set each dice fair and the throws do not interfere with the chance,then each world has a probability 1/36.Probabilistic assertions are usually not about particular worlds,but about sets of them.For example, we might be interested in cases where doubles are rolled,such sets are called events.Such events are described in AI as propositions,in a formal language.The probability associated with a proposition is definedto be the sum of the probabilities of the worlds in which it holds.For example, the probability of the event where doubles are rolled,is probability of doubles is probability of having (1,1)plus probability of having to (2,2) plus probability having (3,3) and so on.There are six of them, and each has probability of 1/36so total probability is 1/6.Probability is like probability of having doubles or probabilityof the total being 11 are called unconditional or prior probabilities.This represents the degree of belief that proposition in the absenceof any other information or evidence.If we have some evidence, for example, the first die is showing five,in this case, we are interested in the conditionalor posterior probability of rolling doubles.Probability of doubles given die one is five.If a patient is going to then to [?] and the prior of cavity, maybe 0.2,but if a patient goes to a dentist because of toothache, then the patientis more interested in the posterior probability.It can be higher probability cavity given to stake, maybe 0.6.Posterior probabilities are defined as probability of A given B equalsprobability of A and B divided probability of B.In our case, the first line, tells that now only rollswhere die one equal five are possible.The probability of this event is 1/6, the sum of six of 1/6 is 1/36.Amongst them, we are interested in only one world,probability of having two fives, and this probability is 1/36.The definition of conditional probability can be rewritten in a different formas a product rule.For two events A and B to be true at the same time, B has to be true,and also A given B has to be true.Variables in probability theory are called random variables.Every random variable has a domain, the set of possible values it can take.The domain of the variable die one is one, two, three, four, five, six.The domain of the variable weather be sunny, rain, cloudy, snow.We can talk about probabilities of all possible values.Probability of weather being sunny is 0.6.Obviously, we're not talking about Britain,probability of weather being rain, 0.1,being cloud is 0.29, and snow 0.01.Only one world is possible at any time point,only one value for the weather so the total probability of all valuesis always one because at least something of all those worldswould happen.This is a probability distribution of the random variable weather.We can consider probability distributions of several variables at the same time.That is a joint probability distribution.For example, probability of weather and toothache.The last notion, we will consider in this mini-lecture is independence.Two events, A and B are independentif probability of A given Bis equal probability of A.The fact that B has happened has no effect on A happening.For example, if A is sunny day, and B is oil price is up,the day is sunny independently of the oil price.Example of a dependent event is a sunny dayand the sale of ice cream is up.A and B are not independent because sale of ice creamis up on sunny days.They are dependent but dependencedoes not necessarily mean causality, it may.In this case, a sunny day indeed can be the reason for sales of ice creamto go up but it's not always the case and one needs to be carefulwith causality.Events can be dependent, but not be a cause of one each other.In this mini-lecture, we briefly refreshed our knowledge about probabilities.Please refer to probability theoryfor the full list of formulas and tools."
}