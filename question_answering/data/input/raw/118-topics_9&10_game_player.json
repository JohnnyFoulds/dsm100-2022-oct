{
  "course": "DSM100-2022-OCT",
  "topic": "Topics 9&10: Game Player",
  "title": "Lecture: Introduction to week 2",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96443&forceview=1",
  "transcript": "[music]Welcome to week two, you came back [chuckles]. What are we going to learn about this week?Well, this week we're digging into the actual mathematical or formal underpinningsof how this Atari game-playing agent is implemented.Here's what we're going to be looking at.First of all, we're going to learn how we can describe a gamein the formalism of a Markov Decision Process.We're doing real AI here because we're using words, formalism, a Markov, so we definitely know that we're doing real AI.Then secondly, we're going to describe what Q-learning isand why it's necessary in the context of playing Atari video games.Finally, we're going to explain the purposeof the key elements in the DQN agent and the loss function.We're going to break down this deep mind, Atari video game playing agentand we're going to understand exactly what it's made of and how it all works in a formal waybefore we go into the coding later in the course.Just some heads up on what we're going to see.This is the agent architecture.We're going to be understanding how the agent architecture works,how this simple diagram here is able to learn how to play video games.Then here's the sort of doom we're going to be looking at this.Don't worry, don't worry.I don't expect you to absorb that all now.I'm going to make my best attempt helping you to understand fully what everything in that equation means.I'm going to break it all apart and explain all the different elements of itand why they're thereand how that means that we're able to learn how to play video games.Later we're going to actually break it apartand look at the actual code where we implement each element of this loss function. That's it. Welcome to week two. I hope you enjoy this kind of formalistic diveinto the implementation of a game-playing AI."
}