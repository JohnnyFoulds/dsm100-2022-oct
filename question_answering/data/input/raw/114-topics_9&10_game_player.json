{
  "course": "DSM100-2022-OCT",
  "topic": "Topics 9&10: Game Player",
  "title": "Lecture: Overview: playing games with AI",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96430&forceview=1",
  "transcript": "[music]In this video, I'm going to tryand lay out some of the themesand flavors of the AI research field,which relates to playing games using AIs.We're going to cover the questionof why we should play games using AIsand what that means?We're going to think abouta few different angles on it.We're going to consider the commercial angle.I'll give you an example of an interestingcommercial requirement of doing this.We'll also look at various research themesand consider certain trendsand things like that in the field,especially looking at Moravec's paradox,and how that's developedinto this idea of general game-playing bots.What do we mean by a game playing AI?Essentially, obviously,maybe AIs that play games.It could be a program that can play chess,a bot that can play Doom,but what is it not?For our purposes, we consider AIs playinggames that a human would play.In other words, we're mainly interestedin AIs playing games where they canpotentially compete against human beings,or their games that human beingsfind really interesting,or that human beings find very challengingbecause it gives us this opportunityto test the progress.Where are we at with AI?That kind of thing.Another reason or a reasonwhy we want to play games?This is from Russelland Norvig's Artificial Intelligence,sort of a classic textbook.They say that games are interestingbecause they're too hard to solve.That sounds like quite a simplistic statement if you like, but actually,they have a whole chapterin the book about itand what they're opening up to us hereis the fact that games containall kinds of really interesting,really hard to solve problems.Things like, if you're playing a fast action game,how do you analyze the visual inputquickly enough so that you can actin an effective way?If you're playing a more long-termstrategy-type game,how do you make sure that you can developa strategy in it and adapt it dynamicallyas conditions change?There's all kinds of classic problems from AIto do with hidden information,planning and visual analysis,all kinds of things that come outwhen you try and play games with AI.Yes, it's really an interesting areafor that reason.Now, this is an interesting paper.Before we look at the quote,I'll just tell you what the paper's about.It's called, When Are We Done with Games?What they're doing in this paper,is from 2019, they're making the argumentthat we're not done with games yet.Because over the last very few years,very recently, it's become apparentthat video games can be played very wellby AIs in particular board games,as well AlphaGo, playing Go, playing chess.AI is brilliant at playing games,and so what they analyze in this paperis how fair those competitions actually are.How fair was it that the OpenAIs Dota Fivewas able to beat a teamof professional players?How fair was that competition?Was it actually as fairas a human-to-human competition typically is?They argue that many of the competitionsare actually not that fair.It's a really interesting paper,it gives an interesting perspective now,but in terms of a motivation for playing games,what did they say there?They say, \"Researchers have consideredStarCraft to be the hardest gamesfor computers to play,which ultimately suggests thatwhen the game is final grand challengefor AI in games before tacklingreal-world problems.\"I said that really fast,but you can summarize it as this.They're basically saying, \"When we're done,if we've solved StarCraft--\"and as we're building on what I was sayingbefore from the Norvig and Russell quote.Once you've solved these games,if you can solve playing StarCraft,you'll have to have solved all kindsof other problems because you haveto act in a complicated,changing situation to achieve certain goalsand collaboration and competition.There's all kinds of things going on in there,which if you solve them,you've definitely solved a load of problems,which would be very useful in the real worldonce you try and apply those AI algorithmsoutside of the game.Next, how about this paper?This is another angle on this.This is a paper from 2018, which bravely claimed--so asked the question,when will AI exceed human performance?Now, you should never ask scientiststo predict when things are going to happen.They don't like doing itand if they really confidentlypredict something,they probably don't knowwhat they're talking aboutor it's already been solved,and then they're hoping you haven't realized yet.Take this with a pinch of salt,but it's really an interesting question.Maybe the most interesting part of this paper is,what are the areas of AIthat they're particularly looking at?Because it gives you an ideaof what were the interesting areas of AIat the time that felt that were being pushedreally hard or weren't being pushed at all.It does give you a map of the field.They asked experts for estimateswhen AI would meet human levelin various tasks.One of the tasks was, when will AIoutperform professional game testerson all Atari Games usingno game-specific knowledge?It's from 2018, a lot of people said 8.5 years.I think the mean predictionwas in 8.5 years from 2018,we'll have a general Atari Game player.I find that a little bit unusual given thatin 2015 DeepMind had already publishedthe Atari DQN player,which we are going to be looking atin the next few weeks,that was able to playquite a few games pretty well.I'm surprised that people saideight years from then, but there you go.What's telling is thatin a general paper about AI,Atari Games came up as a key thingto be looking at.It just shows you that playing theseretro games has become a really importantbenchmark in the field in the 2010s,through to the present day.Actually having said that, in 2020,DeepMind appeared to have solvedthat exact problem.Exactly 2 years after a predictionof 8.5 years was made.That's why you should never predict anything.Moving on, what aboutthe commercial interestin AI gameplay as well?Of course, if you know video games,you know that there's loads of automatedsystems in video games.There's non-player characterswhich react to what you do.There's teammates and there's enemiesand all kinds of things,which appear to exhibit intelligent behaviors.Those are certainly examplesof AIs playing games,but typically they're adversaries,or they've quite limited.What we're more interested in,as I said at the beginning is,AI's doing things that humans would do in the game.Instead of the AI being a part of the game,it's more to do with the AI actuallyplaying the game as if it was a human.Like triggering their control,the controls that a human might send.What about that?This is another interesting paper,all these papers are interesting.That's why I've picked them.This one is a case study from peoplewho work at EA, programmers from EAshowing how they're using AI to playtest games,and the quote is, \"Relying exclusivelyon playtesting conducted by humanscan be costly and inefficient.Artificial agents could performmuch faster play sessions,allowing the exploration of much moreof the game space in much shorter time.\"Basically, if you can train an AIto play a video game,you can then run it offline.It can play, you can have a thousand instancesof it all running at the same time,all playing the gameand trying to find all the bugs.It's really an excellent way of playtesting games,and you'll see that the AI can findall the little flaws in the gameand exploit them.Also, actually, in this particular paper,they were talking about a role-playing gameand they wanted to make sure thatthe balance of difficulty,depending on which role you choseat the beginning of the game,they wanted to make sure that as you workedthrough the game it was equallyas difficult or easy to win,and that there weren't some rolesthat were disadvantaged compared to others.In fact, they did find that some of them were,and they were ableto fine-tune them as a result.That's an interesting one to read as well.What about the role of competitions?Competitions are really importantin video-game-playing AI systemsbecause they allow people to comparethe performance of their system.Now, let's look at these quotes again,this is from Togelius et al,where they were talking aboutthe 2009 Mario AI Competition,which is kind of an early competitionfor playing real video games using AIs.They said that competitions have the roleof providing software interfacesand scoring procedures to fairlyand independently evaluatecompeting algorithms.Fairly and independently comparingthat's great, and the competitionsmotivate researchers.Motivation is good too, because--excuse me [coughs].They motivate researchersbecause existing algorithms get appliedto new areas and the effort neededto participate is less.Basically, competitions make it fairbecause everyone's playing the same game.Everyone's plugginginto the same simulation,so it's really just comparinghow good their AIs are.If everyone's got their own version of the AIof the simulation of Mario,then it's difficult to compare.It's just like benchmarks in any other area of AIand machine learning.Also, it's very motivatingIt is easier to get into because if someone'salready built the simulation,you just need to plug into itand build your AI rather than muckingabout trying to get a simulation to work.I now want to switch modes a little bitand talk about an important trend in the research,which is more of Moravec's paradox.Came from Hans Moravecwho's a very interesting writer on AI.The things that humans find hardare often no problem for AIs, well,not a problem, but they can be solved by AIsand things that humans find easy,not so much.I'll give you an example.I can't beat Garry Kasparov at chess,but in 1997, IBM were able to do thatwith this amazing, super customized computerthat we're going to talk a little bit about later.Whereas when I get up in the morningbefore I'm even awake,I've already got the kettle onand I'm already brewing my first cup of tea.The IBM machine didn't stand a chanceof doing that.It had no arms,it had no visual apparatus it just,it was so specialized it couldn't do anythingbut play chess.All it could do is evaluate gazillionsof chess moves really quickly.That's what we're getting at here is this ideathat the problem is that if we makethese incredibly specific algorithmsthat can only do one thing really, really well,then we're not really creating an AIthat's anything like a human-AI or a general AI.That's led to this trend in the fieldof having game-playing AIsthat can play multiple different games,so and they're generalists.That's trying to address Moravec's paradox.Here's an exampleof general arcade playing games.The DQN which is the onewe're going to be looking at,is one of the earlier kindof retro video game general AI,so the same systemhas to be retrained for each game,but the same basic constructs,the same neural network,the same algorithm can play lots of games.Agent 57 is a state-of-the-art exampleof something that could play all those games.Just to say, there's a whole community of peoplewho've been looking at this for many years.It isn't just DeepMind,although it's tempting to reference thembecause they have these high-hittingnature journal papers but actually there'sa whole community that had been workingon these ideas and developing themfor a long time and I want to acknowledgethose with those two links.Retro arcade games are okay,but what about long-term planning?Actually, if you look into it,some of those Atari games do involvequite long-term planning because you mighthave to search around for agesto find something and then come all the wayback again to somewhere else to use itlike a key or something like that,but nevertheless, compared to somethinglike a Dota or something like that,or StarCraft, then there ismuch more planning involved,and those are maybe more challenging games.The question is when will it end?Let's bring up another quote from the,when are we done with games?\"An ultimate goal that would demonstratethat an AI system can fully master a game,beyond the extrinsic factorsof human versus human competitionswould be to allow anyone to play against itover a long period of time.\"That's what they're saying.They're saying, when AI will be ableto play games as well as humans,when we pretty much try and matchas many of the factors as possible,we basically say, okay,there's a game-playing AI online,and you can just go and play itwhenever you like.Then that's when we'll be confident enoughto say we've solved it and you can playthe game under any conditionsagainst any other player and it will still win.Indeed that's exactlywhat the open AI team have done.They put Donta 5 online and peoplewere able to go in and play against it but again,it was a bit constrained.The reason they're saying thatit was constrained,it could only play in certain circumstances,certain versions of the game,that kind of thing.Also, DeepMind, the AlphaGo,or AlphaStar online so that peoplecould play against that as well.Anyone could log in and playagainst the game player.There have been efforts to do this,but according to these researchers at least,they haven't been entirely fair.That's just giving you a bit of a flavorof this field of game-playing AIs.I've thrown a whole bunch of different ideasat you there just to get you chewing on thisand thinking about it.First of all, we're thinking aboutwhy we play games with AI?What's the motivationand then we're thinking aboutthe commercial aspect to this,just briefly mentioned that ideaof automated playtesting.Going beyond just having automated AIsto play against,but more to do with game testing.Then I pulled out a whole bunchof different research themes,things like the idea of more of Moravec's paradoxwhere we're looking for generalized AIs,and competitions, and benchmarks,and things like that.Thinking about when we're goingto actually decide, yes, we've done this,we've solved this.When do we say we've finishedand what do we do next?In this video,I've just been giving you a nice wide intro to the area of video game and game-playing AIs."
}