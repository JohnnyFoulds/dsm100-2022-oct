{
  "course": "DSM100-2022-OCT",
  "topic": "Topic 2: Problem solving agents",
  "title": "Lecture 7: Optimal search",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96148&forceview=1",
  "transcript": "[music]-In this mini-lecture,we will consider optimal strategies for making decisions.Minimax and Alpha-Beta pruning.In normal search problems,an optimal solution would be a sequence of actionsleading to a goal stateor in case of a game, to a win.In adversarial search,an agent aims to maximize its utility valueby selecting moves that leads to an outcome with the best utility.An agent also acts under the assumptionthat the opponent try to minimize its utility value.Such strategy is called minimax.A minimax search tree is very similarto AND-OR search tree that we considered previously.Max-nodes playing the role of OR-nodes representing actionsby the agent.Min-nodes are playing the role of AND-nodesrepresenting the actions of the opponent.The minimax algorithmis essentially depth-first search algorithm.The minimax algorithm can be extended for more than two players.As we discussed previously,a depth-first search algorithm is grid.It requires exponential amount of time and space to complete the search.Consequently,minimax algorithm is so very demanding.This can be rectified in several ways.Alpha-Beta pruningcan cut away branchesof the search tree that are unlikely to contribute to final solutions.For example, if it is clear that the certain branchescannot supply minimum or maximum values.It is also matterin what order the nodes or moves are selected.If better nodes are selected sooner than larger portionsof a search tree can be pruned.Search strategy can be improved further by utilizing the main knowledge.For example, if an agent remembers previous situations,what move was successful?What moves led to good solutions?The best moves are called killer moves,and the search strategythat is using such moves it called killer move heuristic.The minimax algorithm works with the entire game tree.Alpha-Beta pruning cuts off unpromising branches.For real-time decision,it makes sense to reduce the depths of the searchor length of branches.The rationale for that is that if the decision time is limited,there is no time to do a full-length searchand the search has to be cut off at certain point.Such cut can be fixedor iterative deepening approach can be applied.The minimax and alpha-beta pruningalso can be improvedby replacing a utility function with a heuristic evaluation function.Heuristic evaluation function estimates the utility of the gamefrom a given positionjust as the previously considered heuristic functionestimates the distance to the goal.The performanceof game-playing programs depends stronglyon the quality of its evaluation function.A good evaluation functionwill guide an agent towards the best positions and moves.For example, in chess,an evaluation function can calculate the numberof white pawns, black pawns, white knights, black knights, and so on.These features taken together form categoriesof game states.Certain states may lead to wins more often than others.For example,when category contains all two pawnsversus one pawn end games.It might be known from the previous experiencethat 72% of such situations lead to a win.The environment can beeven more complex than we already discussed.For example, in card games,the environment is stochastic and partially observable.In mini card games,cards are dealt with randomly,with each player receiving a handthat is not visible to other players.Even in such complex situation,minimax and heuristic search still can find good solutions.We have already talked about using domain-specific knowledgefor improving search strategiesand also using the past experience.An intelligent agent can record past moves,analyze which ones were successful and try to use them again.This kind of learning is called meta-learning.A meta-search is a search over other searchesto learn what types of searcheswith what parameters work best in what situations.It is sometimes also called meta-reasoning.Such meta-knowledge is usually transferableto other problems.In this mini-lecture,we discussed optimal decision-making strategies,minimax, and alpha-beta pruning,and also there are modifications to improve their performances.It is particularly important to restrict the search depths in real-time scenarios.An agent may have only minutes, maybe seconds to decide on the next move.In such situation,there is no time to go through the entire search tree.Unpromising branches should be pruned.The depth length should be fixedand heuristic can be applied."
}