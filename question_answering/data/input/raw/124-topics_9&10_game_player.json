{
  "course": "DSM100-2022-OCT",
  "topic": "Topics 9&10: Game Player",
  "title": "Lecture: Weekly outro",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96458&forceview=1",
  "transcript": "[music]Well done, you made it to the end of week two.That was probably the most mathematically challenging weekin this case study. If you found that really dense and difficult to get into,don't worry, we're going to do some coding next weekand we're going to be seeingthe details of how we implement all that maths into code.Certainly for me, I sometimes find it easierto start with the code and work to the maths,but this time we've done it the other way around.What have we been looking at in this rather challenging week?First of all, we've learned how to describe a gamein the formalism of a Markov Decision Process,and it wasn't as complicated as we thought, it's basically states, actions, state-transition matrix,and making decisions iteratively over time.Secondly, we know what Q-learning is and why it's necessary.Q-learning, remember, is the ability to understandwhat value different actions that we might take have,so that we make a decision.Thirdly, we can explain the purpose of the key elements of the DQN agentand the loss function. We've seen the agent architecture now and we've even dug into that loss function,breaking it apartand try to really understand what's going onand what's the magic going on in the DQN agent,which isn't magic at all, of course, it's mathematics. Well done, you've made it to the end of week two,this was probably the most mathematically challenging week.I hope you come back next week to see come code."
}