{
  "course": "DSM100-2022-OCT",
  "topic": "Topic 1: Introduction",
  "title": "Lecture 5: Reflex agents",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96090&forceview=1",
  "transcript": "[music]In the previous mini lectures,we talked about behavior of rational agents and their environments.In this mini lecture, we will look inside an intelligent agent.If before, we talked about how an agent can be specifiedby a mapping of possible percept sequences to actions,today, we will discuss how such a mapping can be implementedas an agent program,a program that takes current percept as an input and outputs and action.The agent program can store also all the necessary knowledgeabout the environment, available actions, and percept history.There are different kinds of agent programs,dependent on how it generates actions,simple reflex agents, model-based reflex agents,utility agents, goal-based agents, and learning agents.We will now briefly discuss these kinds of agent programs.Simple reflex agents are called simplebecause they are taken as an input only the current percept,and they do not store the percept history.For example, the vacuum agent is a simple reflex agentif it makes decisions only based on the current locationand presence or absence of dirt.The program for the vacuum agent might look like the one shownon this slide written in a pseudo-code,function reflex vacuum agent with parameters,location, status, returns, and action.If status is dirty, then it returns action suck.If location is A, then it returns action right.If location is B, then it returns action left.The action program contains condition action rules.For example, if car in front is breaking, then initiate break.You can think about many more examples of such rules.Humans also are using such rules.They may be given, for example, for the current pandemic situation,if entering inside, then put a face mask on,or they can be learned from experience.If calling your friend and then ask how her kid is doing,such rules are also called situation action rules,productions, or simply if-then rules.Obviously, simple reflex agents have limitations.They can work only if a decision can be made based on the current state or the percept and environment.They're not suitable for partially observableor unobservable environments.For example, if in the vacuum agent world,there are many occasions and some are not observable,then the vacuum agent will never clean the whole space.It is not able to decide to move or suck if it is in unknown location.See the rules, it needs a location to initiate the move.Other types of agents are designed to overcome such limitations."
}