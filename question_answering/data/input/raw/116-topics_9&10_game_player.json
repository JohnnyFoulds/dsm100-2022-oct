{
  "course": "DSM100-2022-OCT",
  "topic": "Topics 9&10: Game Player",
  "title": "Lecture: How might we build a game playing AI?",
  "url": "https://learn.london.ac.uk/mod/page/view.php?id=96436&forceview=1",
  "transcript": "-In this video, I'm going to be asking the question,  how do we go about developing a game-playing AI?I'm going to start out by giving us the context,  which is our big aim over the next few weeks  of what we're trying to achieve.Then, we're going to be thinking  about how a human might play a gameand then try and lay that problem out  for an AI system.Then we're going to find out about  what reinforcement learning is as we get to the end and that's the technique  we're going to be using.What's the context?Well, we're going to be looking  in-depth at the DQN agent, which is the deep mind agent from 2015,  which can learn to play Atari video games.The question is why am I doing that?Why am I using that agent which is from 2015?Why not the 2020 one?Why don't you show us the newest one?Well, the reason is there's a certain purity  to the DQN agent,which means we can probably fully understand it  in the time that we have over the next few weeks.We're going to take a really deep dive  into this agent and find out formally how it's been specified looking at  all the formulae and the expressions.Then, look at code implementation  of that and hopefully get it to work and see how it operates.Whereas the later versions, I've found out  actually they've bolted on a load of extra features  which make it perform much better,but it loses some of the purity  of the original agent, which I think is a really impressive piece of work.That's what we're going to be looking at.We're going to be looking at the DQN agent.It plays retro video games.Let's go back and say, how do we go about doing this?How do we go about writing an AI game player and especially one that can play retro video games?What I might do is start out  by playing the game myself.We're going to play this game,  which we've built,  and I'm going to reflect on  what I'm doing as I'm playing it.Just to say that we've built  our own version of Breakoutbecause we can't really show  the Atari one for copyright reasons.Here is the game, which we programmed in Pygame.There's a ball zipping around the screen there.I hit the ball on my bat and every time I hit it,  it gets a bit faster.Eventually, I may have to break through the bricks.You get the idea and it's game over.Let's reflect on what I was doing there,  and just to say, I'm not sure if the original Breakout actually accelerated  the ball in the same way and whatever, but it just gives you the general idea.The questions I was asking myself,  how do I get points?Obviously, games like this,  you're trying to get points.That's the first thing you're thinking about.Then which way is the ball going?I was looking at where the ball  was zipping around on the screen so I could get my bat underneath it.Then I started thinking about the bricks like, \"Oh, where are the bricks?Where do I need to get the ball to go?How can I get the bat in the right position  so the ball bounces off in the right way and I hit the bricks?\"  These are the things I was thinking about.The question is that that's me,  but what about the AI?What is the challenge we're setting the AI here?Well, the way it's built in DQN  in this general Atari game-playing world, so I have my AI and the idea is to give it the minimum,  most realistic information if you like.You want to make it fair,  so it's given the similar informationto what a human would have.I think that that's one of the ideas.Let's just see.We have the game,  which has got the bricks and laid out there, and then there's a ball and a bat.What we could do, we could say,  what we want to do is we're going to tell it exactly where the ball is.We're going to tell it exactly where the bat is,  and we're going to give itall the X and Y positions of all the bricks,  but really the human being, they don't do it like that because the human  doesn't really have that.The human just sees the screen.They just got the visual stimulation of the screen.That's what we do with the AI.The first thing the AI gets is an input,  and literally the pixels of the screen.So the pixels on the screen.Because we don't want it to have to find  the score because how's it going to knowwhat the score is, we cheat a little bit  and do tell it the score and if the game is done.If it's lost or not.Then the output is just a left, right, or nothing.I'm going to use the Northern English expression  for nothing, which is nowt.It's basically the AI as its input,  it has a view of the screen.Literally, the RGB values are the pixels  on the screen, and then it has the score.It has a numerical score, plus a true,  false whether it's lost or not.Then it outputs a left, right or nothing, or nowt.That's the idea.We've tried to create something that's fairly  similar to the way that a human mightplay the game if you like.Now, how are we going to design this AI?Well, yes.Maybe what we could do is just create  a big input-output data set and train a big network, but what does that  data set look like? What's it going to look like?Is it going to going to have every possible screen  that it could ever see?Is it going to say exactly what the correct move  is to make in every possible screen?How do we create that data set?How would it know that in the first place?Do we meticulously label all the millions  of possible screens and different pixel combinations  and label them all as, ''Okay, you should go left here,  you should go right here?'' It's just not really feasible  to create that data set.That's one of the features  we're going to be seeing in the algorithm.Look, what I'm going to do now  is I'm going to give you a definition of reinforcement learning, and hopefully,  now you thought about the game and what the possibilities are,  you'll see that it makes sense.Reinforcement learning is how agents  can learn what to do in the absence of labeled examples of what to do.That's exactly what I'm talking about now.I'm saying it's not really feasible  to create labeled examplesof all the possible screens plus  the correct move to make in every screen.We can't really create that data set.It means that reinforcement learning  with this definition,how agents can learn what to do  in the absence of labeled.That's great.Secondly, imagine playing a new game  whose rules you don't know.After 100 or so moves,  your opponent announces you lose.This is reinforcement learning in a nutshell.That's Russell and Norvig's chapter  on reinforcement learning.It's pretty much what we are looking at.We're playing this game  and these pixels are flowing into us and there's this score, which may or may not go up.Every frame, we get a new shot of the screen.At some point in that, suddenly the game ends  because we moved the wrong way.That's what reinforcement learning algorithms  are aiming to solve.That kind of situation where you've got  this mysterious game, you make a bunch of moves  and then you lose most of the time.The conclusion is we do need  reinforcement learning.It seems based on Russell  and Norvig's description, it seems like a very appropriate set of algorithms  to be investigating.Next week, what we're going to do  is we are going to be formally describingthe reinforcement learning problem in terms  of the actual equations that are in the paper.For now, before we head off, we're going  to think about states, actions, and rewards.Those are the key elements, if you like,  of a reinforcement learning algorithm.The states are, think about that,  if you're looking at the screen going back again to this, the states are really the pixels  coming in and the score or the done.That's the state, if you like.Then the actions are those three actions  we have there: left, right, or nowt.The rewards, I suppose those are the points  or the done, actually.The state is really the screen.The rewards are the points or the done coming inand the actions, the left, right, and done.What we're going to find out  is how we can formalize thatin terms of reinforcement learning  and then how we can build algorithms, which can operate on that formalism  to solve the problem.That's kicking off us thinking  about what gameplaying AIs and how they might operate, especially reinforcement learning  type of game-playing AIs.We've seen the context, which is that we're aiming  to get a really good understandingof this DQN agent,  which can play Atari video games.We've looked at how a human plays a game  and thought about what they can see,what they can do, and what they're trying to do.Then we've tried to outline  the same problem, but for an AIwhere it has limited access  to what's going on in the gamebased on just having the screen and so on.Finally, we've made an argument  of why reinforcement learning looks like an appropriate set of techniques  to use in this context.In this video,  we've just been introducing the concept of how we might go about building  a game-playing AI for the first time."
}